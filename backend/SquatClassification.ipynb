{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "XxeRRKWoEw5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Res Block"
      ],
      "metadata": {
        "id": "TN8HJ28FHOzA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EmjSwZIAD2Qc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single residual layer with three Conv-BN-ReLU stacks and a skip connection.\n",
        "    \"\"\"\n",
        "    def __init__(self, channels=256, kernel_size=3, stride=1, downsample=False):\n",
        "        super(ResBlock, self).__init__()\n",
        "\n",
        "        new_stride = 2 if downsample else 1\n",
        "\n",
        "        self.conv1 = nn.Conv1d(channels, channels,\n",
        "                               kernel_size=kernel_size,\n",
        "                               stride=new_stride,\n",
        "                               padding=kernel_size // 2)\n",
        "        self.bn1 = nn.BatchNorm1d(channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(channels, channels,\n",
        "                               kernel_size=kernel_size,\n",
        "                               stride=1,\n",
        "                               padding=kernel_size // 2)\n",
        "        self.bn2 = nn.BatchNorm1d(channels)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(channels, channels,\n",
        "                               kernel_size=kernel_size,\n",
        "                               stride=1,\n",
        "                               padding=kernel_size // 2)\n",
        "        self.bn3 = nn.BatchNorm1d(channels)\n",
        "\n",
        "        if downsample:\n",
        "          self.skip = nn.Sequential(\n",
        "            nn.Conv1d(channels, channels, kernel_size=1, stride=2, padding=0),\n",
        "            nn.BatchNorm1d(channels)\n",
        "          )\n",
        "        else:\n",
        "          self.skip = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.skip(x)\n",
        "\n",
        "        # First conv + BN + ReLU\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        # Second conv + BN + ReLU\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        # Third conv + BN + ReLU\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        # Add skip connection\n",
        "        out = out + identity\n",
        "\n",
        "        out = self.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, channels, kernel_size=3, dilation=1):\n",
        "        super().__init__()\n",
        "        pad = ((kernel_size - 1) * dilation) // 2\n",
        "        # First dilated conv\n",
        "        self.conv1 = nn.Conv1d(channels, channels,\n",
        "                               kernel_size=kernel_size,\n",
        "                               dilation=dilation,\n",
        "                               padding=pad)\n",
        "        self.bn1   = nn.BatchNorm1d(channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        # Second dilated conv (same params)\n",
        "        self.conv2 = nn.Conv1d(channels, channels,\n",
        "                               kernel_size=kernel_size,\n",
        "                               dilation=dilation,\n",
        "                               padding=pad)\n",
        "        self.bn2   = nn.BatchNorm1d(channels)\n",
        "        # Final activation\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.relu1(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = self.dropout(out)\n",
        "        out = out + identity\n",
        "        return self.relu2(out)"
      ],
      "metadata": {
        "id": "bac6YR80DzFp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full Network"
      ],
      "metadata": {
        "id": "F2DCioLPHQpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SquatResNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the network from your figure (left):\n",
        "      1) conv(3, 2, 256) + BN + ReLU\n",
        "      2) 4 x ResBlock (the structure on the right)\n",
        "      3) AdaptiveAvgPool1d(1)\n",
        "      4) conv(1, 2, 256) + BN\n",
        "      5) Final output dimension is (batch_size, 256, 1) in the time axis\n",
        "         (assuming the stride=2 doesn't collapse it completely).\n",
        "\n",
        "    If you need a classification output (e.g. good vs. bad squat),\n",
        "    you can add a final linear layer or conv layer to produce 2 logits.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 input_channels=528,   # e.g., 3 if each \"time step\" has 3 features\n",
        "                 kernel_size=3,\n",
        "                 stride=2,\n",
        "                 base_channels=128,\n",
        "                 num_res_layers=4):\n",
        "        super(SquatResNet, self).__init__()\n",
        "\n",
        "        # 1) Initial Conv(3, 2, 256):\n",
        "        #    kernel_size=3, stride=2, out_channels=256\n",
        "        #    We'll pad = kernel_size//2 to maintain shape in convolution\n",
        "        self.conv1 = nn.Conv1d(input_channels, base_channels,\n",
        "                               kernel_size=kernel_size,\n",
        "                              #  stride=stride,\n",
        "                               stride=1,\n",
        "                              #  padding=kernel_size // 2\n",
        "                               padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(base_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(p=0.4)\n",
        "\n",
        "        # 2) 4 Residual Layers\n",
        "        layers = []\n",
        "        for i in range(num_res_layers//2):\n",
        "            down = (i % 2 == 0)\n",
        "            # down = True\n",
        "            layers.append(ResBlock(channels=base_channels, kernel_size=kernel_size, stride=1, downsample=down))\n",
        "            # if (i % 2 == 0):\n",
        "            #   layers.append(nn.Dropout(p=0.3))\n",
        "\n",
        "        for i in range(2, 4):\n",
        "            layers.append(DilatedResBlock(channels=base_channels, kernel_size=kernel_size, dilation=i))\n",
        "\n",
        "        # layers.append(nn.Dropout(p=0.3))\n",
        "        self.res_layers = nn.Sequential(*layers)\n",
        "\n",
        "        # 3) Adaptive Average Pool -> output size = 1 in the time dimension\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        # Optional: final classifier\n",
        "        # For a 2-class problem, you can add a linear layer or another conv:\n",
        "        self.fc = nn.Linear(base_channels, 2)\n",
        "        # or a final conv1d with out_channels=2, kernel_size=1, stride=1, etc.\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x shape: (batch_size, input_channels, time_length)\n",
        "        \"\"\"\n",
        "        # 1) Initial conv + BN + ReLU\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        # x = self.dropout(x)\n",
        "\n",
        "        # 2) Residual layers\n",
        "        x = self.res_layers(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # 3) Adaptive average pooling -> (batch_size, base_channels, 1)\n",
        "        x = self.avgpool(x)\n",
        "\n",
        "        # You might want a final classifier. For example:\n",
        "        x = F.relu(x)\n",
        "        x = x.squeeze(-1)               # (batch_size, base_channels)\n",
        "        x = self.fc(x)            # (batch_size, 2)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "bq9amqZzHRyK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Fd7N97cGzg9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class SquatDataset(Dataset):\n",
        "    def __init__(self, mats, labels, max_frames=100):\n",
        "        self.tensors = []\n",
        "        for mat in mats:\n",
        "          if isinstance(mat, np.ndarray) and mat.dtype == np.object_:\n",
        "            mat = np.array(mat.tolist(), dtype=np.float32)  # convert from object array to regular float array\n",
        "          else:\n",
        "            mat = np.array(mat, dtype=np.float32)\n",
        "          t = np.linspace(0, 1, mat.shape[1])\n",
        "          mat = np.vstack([mat, t])\n",
        "          mat = torch.tensor(mat, dtype=torch.float32)\n",
        "          mat = (mat - mat.mean(dim=1, keepdim=True)) / (mat.std(dim=1, keepdim=True) + 1e-6)\n",
        "          self.tensors.append(mat)\n",
        "\n",
        "        self.label_numbers = torch.tensor(labels, dtype=torch.long)\n",
        "        self.max_frames = max_frames\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tensors)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mat = self.tensors[idx]\n",
        "        label_nums = self.label_numbers[idx]\n",
        "\n",
        "        return mat, label_nums"
      ],
      "metadata": {
        "id": "XQ7NVvxzzycQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Up Training"
      ],
      "metadata": {
        "id": "r1FQ0AoKdPcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mats = np.load(\"/content/mats_small.npy\", allow_pickle=True)\n",
        "labels = np.load(\"/content/labels_small.npy\")\n",
        "\n",
        "cnt = 0\n",
        "for i in range(len(labels)):\n",
        "  if labels[i] == 1:\n",
        "    cnt+=1\n",
        "\n",
        "print(cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bMyE21QdLDB",
        "outputId": "25d2c26d-1196-423a-980c-beddb218e904"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = SquatDataset(mats, labels)\n",
        "# train_dataset, val_dataset, test_dataset = random_split(dataset, [0.8, 0.1, 0.1], generator=torch.Generator().manual_seed(42))\n",
        "train_mats, val_mats, train_labels, val_labels = train_test_split(\n",
        "    mats, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "# Then wrap each in your Dataset\n",
        "train_dataset = SquatDataset(train_mats, train_labels)\n",
        "val_dataset   = SquatDataset(val_mats,   val_labels)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
        "# test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "best_val_loss = 100.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPVLQd3xrjyz",
        "outputId": "437271cf-c4c7-4b1d-bd9d-64b8f65d7992"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Baseline Model"
      ],
      "metadata": {
        "id": "gAPZe-GzmJMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleResBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(channels, channels, 3, padding=1)\n",
        "        self.bn1   = nn.BatchNorm1d(channels)\n",
        "        self.conv2 = nn.Conv1d(channels, channels, 3, padding=1)\n",
        "        self.bn2   = nn.BatchNorm1d(channels)\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        return F.relu(out + identity)\n",
        "\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(528, 256, kernel_size=3, padding=1)\n",
        "        self.bn1   = nn.BatchNorm1d(256)\n",
        "        self.conv2 = nn.Conv1d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn2   = nn.BatchNorm1d(256)\n",
        "        self.conv3 = nn.Conv1d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn3   = nn.BatchNorm1d(256)\n",
        "        self.pool  = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc    = nn.Linear(256, 2)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn2(self.conv3(x)))\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "XcuXQ2qGmNPu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SquatHybrid(nn.Module):\n",
        "    def __init__(self, input_channels=528, base_channels=128, num_res_layers=4):\n",
        "        super().__init__()\n",
        "        # 1) Initial conv + ResLayers (same as yours)\n",
        "        self.conv1 = nn.Conv1d(input_channels, base_channels, 3, padding=1)\n",
        "        self.bn1   = nn.BatchNorm1d(base_channels)\n",
        "        self.relu  = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        layers = []\n",
        "        for i in range(num_res_layers//2):\n",
        "            down = (i % 2 == 0)\n",
        "            # down = True\n",
        "            layers.append(ResBlock(channels=base_channels, kernel_size=3, stride=1, downsample=down))\n",
        "            # if (i % 2 == 0):\n",
        "            #   layers.append(nn.Dropout(p=0.3))\n",
        "\n",
        "        for i in range(2, 4):\n",
        "            layers.append(DilatedResBlock(channels=base_channels, kernel_size=3, dilation=i))\n",
        "\n",
        "        # layers.append(nn.Dropout(p=0.3))\n",
        "        self.res_layers = nn.Sequential(*layers)\n",
        "        # 2) Sequence model: pick one\n",
        "        # a) Bi-LSTM\n",
        "        # self.lstm = nn.LSTM(base_channels, base_channels, batch_first=True,\n",
        "        #                     bidirectional=True, num_layers=1)\n",
        "        # self.fc   = nn.Linear(base_channels*2, 2)\n",
        "        # OR b) Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=base_channels, nhead=4, batch_first=True, dropout=0.5)\n",
        "        self.transf = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "        self.fc    = nn.Linear(base_channels, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B,528,T)\n",
        "        x = self.relu(self.bn1(self.conv1(x)))        # (B, C, T)\n",
        "        x = self.res_layers(x)                                # (B, C, T)\n",
        "        x = x.permute(0,2,1)                           # (B, T, C) for seq models\n",
        "\n",
        "        # a) LSTM path\n",
        "        # out, _ = self.lstm(x)                          # (B, T, 2C)\n",
        "        # out     = out.mean(1)                          # average over time → (B, 2C)\n",
        "\n",
        "        # b) Transformer path (uncomment if using)\n",
        "        # out = x.permute(1,0,2)  # (T,B,C)\n",
        "        x = self.transf(x)  # (T,B,C)\n",
        "        x = x.mean(dim=1)       # → (B,C)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "a7tIICvRGoRD"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Cycle"
      ],
      "metadata": {
        "id": "WFP0MxigdRVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SquatResNet(input_channels=529).to(device) # Define model\n",
        "# model = SquatHybrid(input_channels=529).to(device)\n",
        "\n",
        "counts = np.bincount(train_labels)           # e.g. [800, 200]\n",
        "weights = 1.0 / counts                   # inverse frequency\n",
        "class_weights = weights / weights.sum()  # normalize\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1, weight=torch.tensor(class_weights, dtype=torch.float32).to(device))\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=2e-3,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    steps_per_epoch=len(train_dataloader),\n",
        "    pct_start=0.3\n",
        ")"
      ],
      "metadata": {
        "id": "Upi4jmBNkU3K"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ***If model already been trained, load model)\n",
        "# if os.path.exists(\"/content/model.pth\"):\n",
        "#   model.load_state_dict(torch.load(\"/content/model.pth\", map_location=device))\n",
        "# else:\n",
        "#   model = SquatResNet().to(device) # Define model\n",
        "# Train the model\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, targets in train_dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        assert targets.dtype == torch.long\n",
        "        assert targets.max() <= 1\n",
        "        assert targets.min() >= 0\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validate the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "        for inputs, targets in val_dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            assert targets.dtype == torch.long\n",
        "            assert targets.max() <= 1\n",
        "            assert targets.min() >= 0\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            predictions = torch.argmax(outputs, dim=1)\n",
        "            correct += (predictions.cpu() == targets.cpu()).sum().item()\n",
        "            total += targets.size(0)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), \"/content/model.pth\")\n",
        "            print(\"Best loss:\", best_val_loss)\n",
        "        # Test the model\n",
        "        test_loss = 0.0\n",
        "        # for inputs, targets in test_dataloader:\n",
        "        #     inputs = inputs.to(device)\n",
        "        #     targets = targets.to(device)\n",
        "        #     outputs = model(inputs)\n",
        "        #     loss = loss_fn(outputs, targets)\n",
        "        #     test_loss += loss.item()\n",
        "    val_acc = correct / total\n",
        "\n",
        "    # if (epoch+1) % 10 == 0:\n",
        "    # print(f\"Epoch {epoch}, Train Loss: {train_loss / len(train_dataloader)}, Val Loss: {val_loss / len(val_dataloader)}, Test Loss: {test_loss / len(test_dataloader)}\")\n",
        "    print(f\"Epoch {epoch}, Train Loss: {train_loss / len(train_dataloader)}, Val Loss: {val_loss / len(val_dataloader)}, Val Accuracy: {val_acc}\")\n",
        "\n",
        "# ***Save model****\n",
        "# torch.save(model.state_dict(), \"/content/model.pth\")\n"
      ],
      "metadata": {
        "id": "6bBLliuEE4ew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d6433d-0136-4055-99f9-db00b49504d5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 0.8987034857273102, Val Loss: 0.6981440782546997, Val Accuracy: 0.5\n",
            "Epoch 1, Train Loss: 0.7715025246143341, Val Loss: 0.6989044547080994, Val Accuracy: 0.5\n",
            "Epoch 2, Train Loss: 0.5904654860496521, Val Loss: 0.6937092542648315, Val Accuracy: 0.49056603773584906\n",
            "Epoch 3, Train Loss: 0.5616771876811981, Val Loss: 0.6948764324188232, Val Accuracy: 0.4811320754716981\n",
            "Epoch 4, Train Loss: 0.434390589594841, Val Loss: 0.6957876682281494, Val Accuracy: 0.5283018867924528\n",
            "Epoch 5, Train Loss: 0.5597544014453888, Val Loss: 0.6923713684082031, Val Accuracy: 0.6037735849056604\n",
            "Epoch 6, Train Loss: 0.43800026178359985, Val Loss: 0.8162083625793457, Val Accuracy: 0.5283018867924528\n",
            "Epoch 7, Train Loss: 0.4013144075870514, Val Loss: 0.7959104776382446, Val Accuracy: 0.5188679245283019\n",
            "Epoch 8, Train Loss: 0.31558799743652344, Val Loss: 0.8141824007034302, Val Accuracy: 0.5283018867924528\n",
            "Epoch 9, Train Loss: 0.30789582431316376, Val Loss: 0.7974138259887695, Val Accuracy: 0.5660377358490566\n",
            "Epoch 10, Train Loss: 0.2609460800886154, Val Loss: 0.9838725328445435, Val Accuracy: 0.5283018867924528\n",
            "Epoch 11, Train Loss: 0.24656790494918823, Val Loss: 0.8722279667854309, Val Accuracy: 0.5754716981132075\n",
            "Epoch 12, Train Loss: 0.2417244240641594, Val Loss: 0.8628171682357788, Val Accuracy: 0.5188679245283019\n",
            "Epoch 13, Train Loss: 0.22559688240289688, Val Loss: 0.7971971035003662, Val Accuracy: 0.5377358490566038\n",
            "Epoch 14, Train Loss: 0.21852728724479675, Val Loss: 0.7686350345611572, Val Accuracy: 0.5283018867924528\n",
            "Epoch 15, Train Loss: 0.21945422887802124, Val Loss: 0.7746190428733826, Val Accuracy: 0.5754716981132075\n",
            "Epoch 16, Train Loss: 0.21557144075632095, Val Loss: 0.7923710346221924, Val Accuracy: 0.5754716981132075\n",
            "Epoch 17, Train Loss: 0.2114638090133667, Val Loss: 0.8085994720458984, Val Accuracy: 0.6037735849056604\n",
            "Epoch 18, Train Loss: 0.21461071074008942, Val Loss: 0.8207858204841614, Val Accuracy: 0.6037735849056604\n",
            "Epoch 19, Train Loss: 0.20941142737865448, Val Loss: 0.8291656374931335, Val Accuracy: 0.6132075471698113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "ZOj43Ka83uDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Load trained model weights (skip this if model was just trained in this session)\n",
        "# torch.save(model.state_dict(), \"squat_model.pth\")  <-- save after training (one-time)\n",
        "model = SquatResNet().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/model.pth\", map_location=device))  # make sure model is saved first\n",
        "model.eval()\n",
        "\n",
        "# Load the new pose matrix (.npy file) for inference\n",
        "pose_matrix = np.load(\"pose_matrix.npy\")  # shape: (528, T)\n",
        "tensor = torch.tensor(pose_matrix, dtype=torch.float32).unsqueeze(0).to(device)  # shape: (1, 528, T)\n",
        "\n",
        "# Run the model to get prediction\n",
        "with torch.no_grad():\n",
        "    logits = model(tensor)  # shape: (1, 2)\n",
        "    probs = F.softmax(logits, dim=1)  # convert logits to probabilities\n",
        "    pred = torch.argmax(probs, dim=1).item()  # get predicted class (0 or 1)\n",
        "    conf = probs[0][pred].item()  # get confidence of the predicted class\n",
        "\n",
        "# Map prediction to label\n",
        "label_map = {0: \"Bad Squat\", 1: \"Good Squat\"}\n",
        "print(f\"✅ Your squat is {conf * 100:.2f}% {label_map[pred].lower()}.\")\n"
      ],
      "metadata": {
        "id": "bzlMFMcdzWEd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}